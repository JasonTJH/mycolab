{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "USEquityML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonTJH/mycolab/blob/main/USEquityML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaHScvdFuGtl"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNxWdwuA6AER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ae0ecd-0e43-4072-8e1a-3a92b3edc7a2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHTRxnoQIqPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5317799f-292a-4363-dbd3-4190d8675f57"
      },
      "source": [
        "# Visualization\n",
        "#from openpyxl.workbook import Workbook\n",
        "#from openpyxl import load_workbook\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Machine Learning\n",
        "from sklearn import preprocessing, neighbors, svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.cluster import KMeans, MeanShift\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# For oversampling to balance the dataset\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# Results Analysis\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score, roc_curve\n",
        "#Model weight manipulation (may cause overfitting though)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pylab import rcParams\n",
        "#\n",
        "from timeit import default_timer as timer\n",
        "sns.set()\n",
        "\n",
        "#from numba import jit, njit\n",
        "#GPU VERSIONS\n",
        "#import cupy as np\n",
        "#import cudf as pd\n",
        "#import cuml as sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GSi43LCIqQJ"
      },
      "source": [
        "def get_df(path: str):\n",
        "  return pd.read_excel(path)\n",
        "\n",
        "def add_hurdle_col(dataframe,hurdle):\n",
        "  #Add new col\n",
        "  dataframe.loc[dataframe['Fwd 5Y Return'] >= hurdle, 'Y'] = 1\n",
        "  dataframe.loc[dataframe['Fwd 5Y Return'] < hurdle, 'Y'] = 0\n",
        "\n",
        "def get_base_prob(dataframe):\n",
        "  base_probability = round(len(dataframe[(dataframe['Y']==1)])/len(dataframe),2)\n",
        "  return base_probability\n",
        "\n",
        "def drop_useless_cols(dataframe):\n",
        "  # Drop useless columns\n",
        "  dataframe = dataframe.drop(['Ticker','Name'],axis=1)\n",
        "  return dataframe\n",
        "\n",
        "def clean_div_yield_col(dataframe):\n",
        "  # Clean dividend yield column\n",
        "  dataframe['Dvd Yld'] = dataframe['Dvd Yld'].str[:-1].astype(float)\n",
        "\n",
        "def clean_KMB_all_cols(dataframe):\n",
        "  # Clean K, M, B from all columns\n",
        "  repl_dict = {'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9'}\n",
        "  for col in dataframe:\n",
        "      try:\n",
        "          dataframe[col] = dataframe[col].replace(repl_dict, regex=True).map(pd.eval).astype(float)\n",
        "      except:\n",
        "          None\n",
        "\n",
        "def get_xy(dataframe):\n",
        "  #Data Selection/Preparation (X and y are dataframes)\n",
        "  X = dataframe.drop(['Fwd 5Y Return','Y','As of date'],1)\n",
        "  y = dataframe['Y'].to_frame()\n",
        "  return X,y\n",
        "\n",
        "def get_oversampled_df(X,y):\n",
        "  #Data Oversampling for balancing\n",
        "  X_resampled, y_resampled = SMOTE(random_state=0).fit_resample(X,y.values.ravel())\n",
        "  #Create oversampled df\n",
        "  oversampled_df = pd.DataFrame(X_resampled, columns=X.columns).join(pd.DataFrame(y_resampled, columns=y.columns))\n",
        "  return oversampled_df\n",
        "\n",
        "def join_df(X,y):\n",
        "  #Create oversampled df\n",
        "  new_df = X.join(y)\n",
        "  return new_df\n",
        "\n",
        "def get_scaled_xy(dataframe):\n",
        "  #Change X and y to np arrays for input into models\n",
        "  X = np.array(dataframe.drop(['Y'],1))\n",
        "  y = np.array(dataframe['Y'])\n",
        "  #Data Scaling\n",
        "  scaler = RobustScaler(quantile_range=(5, 95))\n",
        "  X = scaler.fit_transform(X)\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVSkqgUTIqRZ"
      },
      "source": [
        "def get_EP_results(K_Means_nclusters:int,Mean_Shift_min_df_len:float,base_test_prob:float,X_train, y_train,X_test, y_test,train_date,test_date):\n",
        "\n",
        "  EP = {'DT' : DT(X_train, y_train,X_test, y_test)-base_test_prob,\n",
        "        'KNN' : KNN(X_train, y_train,X_test, y_test)-base_test_prob,\n",
        "        'RF' : RF(X_train, y_train,X_test, y_test)-base_test_prob,\n",
        "        'SVM' : SVM(X_train, y_train,X_test, y_test)-base_test_prob,\n",
        "        'KMeans' : K_Means(K_Means_nclusters,X_train, y_train,X_test, y_test)-base_test_prob}#,\n",
        "        #'MeanShift' : Mean_Shift(df,Mean_Shift_min_df_len)-base_prob}\n",
        "  \n",
        "  EP = {k: round(v,2) for k, v in EP.items()}\n",
        "  \n",
        "  x = (f\"Decision Tree:\\t\\t{EP['DT']}\\\n",
        "      \\nK Nearest Neighbors:\\t{EP['KNN']}\\\n",
        "      \\nRandom Forest:\\t\\t{EP['RF']}\\\n",
        "      \\nSupport Vector Machine:\\t{EP['SVM']}\\\n",
        "      \\nK Means Clustering:\\t{EP['KMeans']})\")\n",
        "      #\\nMean Shift:\\t\\t{EP['MeanShift']}\")\n",
        "\n",
        "  bestalgo = {'Algo':max(EP,key=EP.get),\n",
        "            'ExProb':max(EP.values()),\n",
        "            'BaseProb':base_prob if max(EP,key=EP.get) == 'MeanShift' else base_test_prob,\n",
        "            'Precision':round(max(EP.values()) + (base_prob if max(EP,key=EP.get) == 'MeanShift' else base_test_prob),2),\n",
        "            'Traindate':train_date,\n",
        "            'Testdate':test_date}\n",
        "      \n",
        "  y = (f\"The Best Algorithm:\\t{bestalgo['Algo']}\\\n",
        "      \\nExcess probability:\\t{bestalgo['ExProb']}\\\n",
        "      \\nBase probability:\\t{bestalgo['BaseProb']}\\\n",
        "      \\n\\\n",
        "      \\nTrain date:\\t\\t{bestalgo['Traindate']}\\\n",
        "      \\nTest date:\\t\\t{bestalgo['Testdate']}\")\n",
        "  \n",
        "  #EP['base_prob'] = base_prob\n",
        "  EP['base_test_prob'] = base_test_prob\n",
        "  \n",
        "  return EP, bestalgo, f\"Excess Probabilities\\n\\n{x}\\n\\n{y}\"\n",
        "\n",
        "def store_results(result_to_store,resultdict,train_date,test_date,hurdle):\n",
        "  resultdict[f'{hurdle*100}%//{train_date}//{test_date}'] = result_to_store"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E6R7RYevEfL"
      },
      "source": [
        "# Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1nFDA82IqQq"
      },
      "source": [
        "def DT(X_train, y_train,X_test, y_test):\n",
        "  # Decision Tree\n",
        "  clf = DecisionTreeClassifier()\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_predict = clf.predict(X_test)\n",
        "  return precision_score(y_test,y_predict,zero_division=0)\n",
        "\n",
        "def KNN(X_train, y_train,X_test, y_test):\n",
        "  # K Nearest Neighbors\n",
        "  clf = neighbors.KNeighborsClassifier()\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_predict = clf.predict(X_test)\n",
        "  return precision_score(y_test,y_predict,zero_division=0)\n",
        "\n",
        "def RF(X_train, y_train,X_test, y_test):\n",
        "  # Random Forest\n",
        "  clf = RandomForestClassifier()\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_predict = clf.predict(X_test)\n",
        "  return precision_score(y_test,y_predict,zero_division=0)\n",
        "\n",
        "def SVM(X_train, y_train,X_test, y_test):\n",
        "  # Support Vector Machine\n",
        "  clf = svm.SVC(kernel='rbf', C=1)\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_predict = clf.predict(X_test)\n",
        "  return precision_score(y_test,y_predict,zero_division=0)\n",
        "\n",
        "def K_Means(num_clusters,X_train, y_train,X_test, y_test):\n",
        "  # K Means Clustering (unsupervised)\n",
        "  clf = KMeans(n_clusters=num_clusters)\n",
        "  clf.fit(X_train)\n",
        "  postivepred = 0\n",
        "  correct_pos = 0\n",
        "  for i in range(len(X_test)):\n",
        "      predict_me = np.array(X_test[i].astype(float))\n",
        "      predict_me = predict_me.reshape(-1,len(predict_me))\n",
        "      prediction = clf.predict(predict_me)\n",
        "      if prediction[0] == np.ones(1):\n",
        "        postivepred+=1\n",
        "        if prediction[0] == y_test[i]:\n",
        "          correct_pos+=1\n",
        "  precision = correct_pos/postivepred if postivepred > 0 else 0\n",
        "  return precision\n",
        "\n",
        "def Mean_Shift(dataframe,min_df_len,X_train, y_train,X_test, y_test):\n",
        "  # Means Shift (unsupervised)\n",
        "  clf = MeanShift()\n",
        "  clf.fit(X)\n",
        "  labels = clf.labels_\n",
        "  cluster_centers = clf.cluster_centers_\n",
        "  dataframe['cluster_group'] = labels\n",
        "  n_clusters_= len(np.unique(labels))\n",
        "  correct_rates = {}\n",
        "\n",
        "  for i in range(n_clusters_):\n",
        "      temp_df = dataframe.loc[(dataframe[\"cluster_group\"] == float(i))].copy()\n",
        "      correct_cluster = temp_df.loc[(temp_df[\"Y\"] == 1)].copy()\n",
        "      correct_rate = len(correct_cluster)/len(temp_df)\n",
        "      if len(temp_df)>min_df_len*len(dataframe):\n",
        "          correct_rates[i]= correct_rate\n",
        "  return max(correct_rates.values())\n",
        "  # MeanShift algo returns the cluster number/key i/o underlying binary outcomes.\n",
        "  # Already using precision (we are choosing the cluster with best precision)\n",
        "  # This algorithm is very slow...."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww7a1X_ZuWW5"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCwem2xgzX9b"
      },
      "source": [
        "## Model for normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-ZZUDlBnOek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0af2c1d-1529-4cd5-bbb0-6492b873ce9f"
      },
      "source": [
        "start = timer()\n",
        "PATH = '/content/drive/My Drive/YOUR_PATH_TO_DATA'\n",
        "result1 = {}\n",
        "\n",
        "#Lists to iterate over\n",
        "#datepairs = [['2010-06-30','2011-06-30']]#,['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]\n",
        "datepairs = [['2011-06-30','2012-06-30'],['2011-06-30','2013-06-30'],['2011-06-30','2014-06-30']]\n",
        "hurdlelist = [1,2,3,4,5] # >x*100% returns in the forward 5Y period\n",
        "\n",
        "for hurdle in hurdlelist:\n",
        "  for datepair in datepairs:\n",
        "    #Setting of parameters\n",
        "    hurdle = hurdle\n",
        "    train_date = datepair[0]\n",
        "    test_date = datepair[1]\n",
        "    K_Means_nclusters = 2\n",
        "    Mean_Shift_min_df_len = 0.1\n",
        "\n",
        "    #-----Start main program-----\n",
        "    df = get_df(PATH)\n",
        "    df = df.loc[(df[\"As of date\"] == train_date)|(df[\"As of date\"] == test_date)]\n",
        "    add_hurdle_col(dataframe=df,hurdle=hurdle)\n",
        "    df = drop_useless_cols(dataframe=df)\n",
        "    clean_div_yield_col(dataframe=df)\n",
        "    clean_KMB_all_cols(dataframe=df)\n",
        "    #-----Start of ML-----\n",
        "    #Get X, y as individual dataframes\n",
        "    X, y = get_xy(dataframe=df)\n",
        "    X_train, y_train = get_xy(dataframe=df.loc[(df[\"As of date\"] == train_date)])\n",
        "    X_test, y_test = get_xy(dataframe=df.loc[(df[\"As of date\"] == test_date)])\n",
        "\n",
        "    train_df = join_df(X_train,y_train)\n",
        "    X_train, y_train = get_scaled_xy(dataframe=train_df)\n",
        "    \n",
        "    #Supervised test\n",
        "    test_df = join_df(X_test,y_test)\n",
        "    base_test_probability = get_base_prob(dataframe=test_df)\n",
        "    X_test, y_test = get_scaled_xy(dataframe=test_df)\n",
        "\n",
        "    df = join_df(X,y)\n",
        "    #base_probability = get_base_prob(dataframe=df)\n",
        "    X, y = get_scaled_xy(dataframe=df)\n",
        "    \n",
        "    EP, bestalgo, summary = get_EP_results(K_Means_nclusters=K_Means_nclusters,Mean_Shift_min_df_len=Mean_Shift_min_df_len,base_test_prob=base_test_probability,\\\n",
        "                                           X_train=X_train, y_train=y_train,X_test=X_test, y_test=y_test,train_date=train_date,test_date=test_date)\n",
        "    store_results(result_to_store=EP,resultdict=result1,train_date=train_date,test_date=test_date,hurdle=hurdle)\n",
        "    #-----End of program-----\n",
        "\n",
        "end = timer()\n",
        "print (end-start)\n",
        "\n",
        "result1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "143.154163621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'100%//2011-06-30//2012-06-30': {'DT': 0.0,\n",
              "  'KMeans': 0.12,\n",
              "  'KNN': 0.02,\n",
              "  'RF': 0.18,\n",
              "  'SVM': -0.38,\n",
              "  'base_test_prob': 0.38},\n",
              " '100%//2011-06-30//2013-06-30': {'DT': 0.01,\n",
              "  'KMeans': -0.29,\n",
              "  'KNN': 0.0,\n",
              "  'RF': -0.0,\n",
              "  'SVM': -0.29,\n",
              "  'base_test_prob': 0.29},\n",
              " '100%//2011-06-30//2014-06-30': {'DT': 0.0,\n",
              "  'KMeans': -0.19,\n",
              "  'KNN': 0.02,\n",
              "  'RF': -0.06,\n",
              "  'SVM': -0.19,\n",
              "  'base_test_prob': 0.19},\n",
              " '200%//2011-06-30//2012-06-30': {'DT': 0.04,\n",
              "  'KMeans': 0.37,\n",
              "  'KNN': 0.12,\n",
              "  'RF': -0.13,\n",
              "  'SVM': -0.13,\n",
              "  'base_test_prob': 0.13},\n",
              " '200%//2011-06-30//2013-06-30': {'DT': -0.0,\n",
              "  'KMeans': -0.09,\n",
              "  'KNN': -0.09,\n",
              "  'RF': -0.09,\n",
              "  'SVM': -0.09,\n",
              "  'base_test_prob': 0.09},\n",
              " '200%//2011-06-30//2014-06-30': {'DT': 0.01,\n",
              "  'KMeans': -0.06,\n",
              "  'KNN': 0.04,\n",
              "  'RF': -0.06,\n",
              "  'SVM': -0.06,\n",
              "  'base_test_prob': 0.06},\n",
              " '300%//2011-06-30//2012-06-30': {'DT': 0.11,\n",
              "  'KMeans': 0.45,\n",
              "  'KNN': -0.05,\n",
              "  'RF': 0.95,\n",
              "  'SVM': -0.05,\n",
              "  'base_test_prob': 0.05},\n",
              " '300%//2011-06-30//2013-06-30': {'DT': 0.05,\n",
              "  'KMeans': -0.04,\n",
              "  'KNN': -0.04,\n",
              "  'RF': -0.04,\n",
              "  'SVM': -0.04,\n",
              "  'base_test_prob': 0.04},\n",
              " '300%//2011-06-30//2014-06-30': {'DT': 0.06,\n",
              "  'KMeans': -0.03,\n",
              "  'KNN': -0.03,\n",
              "  'RF': -0.03,\n",
              "  'SVM': -0.03,\n",
              "  'base_test_prob': 0.03},\n",
              " '400%//2011-06-30//2012-06-30': {'DT': 0.01,\n",
              "  'KMeans': 0.48,\n",
              "  'KNN': -0.02,\n",
              "  'RF': -0.02,\n",
              "  'SVM': -0.02,\n",
              "  'base_test_prob': 0.02},\n",
              " '400%//2011-06-30//2013-06-30': {'DT': 0.03,\n",
              "  'KMeans': -0.02,\n",
              "  'KNN': -0.02,\n",
              "  'RF': -0.02,\n",
              "  'SVM': -0.02,\n",
              "  'base_test_prob': 0.02},\n",
              " '400%//2011-06-30//2014-06-30': {'DT': -0.01,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': -0.01,\n",
              "  'RF': -0.01,\n",
              "  'SVM': -0.01,\n",
              "  'base_test_prob': 0.01},\n",
              " '500%//2011-06-30//2012-06-30': {'DT': -0.01,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': -0.01,\n",
              "  'RF': -0.01,\n",
              "  'SVM': -0.01,\n",
              "  'base_test_prob': 0.01},\n",
              " '500%//2011-06-30//2013-06-30': {'DT': 0.04,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': -0.01,\n",
              "  'RF': -0.01,\n",
              "  'SVM': -0.01,\n",
              "  'base_test_prob': 0.01},\n",
              " '500%//2011-06-30//2014-06-30': {'DT': -0.01,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': -0.01,\n",
              "  'RF': -0.01,\n",
              "  'SVM': -0.01,\n",
              "  'base_test_prob': 0.01}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkP8m6vjzSA1"
      },
      "source": [
        "## Model for oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJsR4GEzzInJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53cba3ed-e63b-47d9-af11-4d4566030223"
      },
      "source": [
        "start = timer()\n",
        "PATH = '/content/drive/My Drive/YOUR_PATH_TO_DATA'\n",
        "result2 = {}\n",
        "\n",
        "#Lists to iterate over\n",
        "#datepairs = [['2010-06-30','2011-06-30']]#,['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]\n",
        "datepairs = [['2011-06-30','2012-06-30'],['2011-06-30','2013-06-30'],['2011-06-30','2014-06-30']]\n",
        "hurdlelist = [1,2,3,4,5] # >x*100% returns in the forward 5Y period\n",
        "\n",
        "for hurdle in hurdlelist:\n",
        "  for datepair in datepairs:\n",
        "    #Setting of parameters\n",
        "    hurdle = hurdle\n",
        "    train_date = datepair[0]\n",
        "    test_date = datepair[1]\n",
        "    K_Means_nclusters = 2\n",
        "    Mean_Shift_min_df_len = 0.1\n",
        "\n",
        "    #-----Start main program-----\n",
        "    df = get_df(PATH)\n",
        "    df = df.loc[(df[\"As of date\"] == train_date)|(df[\"As of date\"] == test_date)]\n",
        "    add_hurdle_col(dataframe=df,hurdle=hurdle)\n",
        "    df = drop_useless_cols(dataframe=df)\n",
        "    clean_div_yield_col(dataframe=df)\n",
        "    clean_KMB_all_cols(dataframe=df)\n",
        "    #-----Start of ML-----\n",
        "    #Get X, y as individual dataframes\n",
        "    X, y = get_xy(dataframe=df)\n",
        "    X_train, y_train = get_xy(dataframe=df.loc[(df[\"As of date\"] == train_date)])\n",
        "    X_test, y_test = get_xy(dataframe=df.loc[(df[\"As of date\"] == test_date)])\n",
        "\n",
        "    #Supervised train\n",
        "    ostrain_df = get_oversampled_df(X_train,y_train)\n",
        "    X_train, y_train = get_scaled_xy(dataframe=ostrain_df)\n",
        "\n",
        "    #Supervised test\n",
        "    test_df = join_df(X_test,y_test)\n",
        "    base_test_probability = get_base_prob(dataframe=test_df)\n",
        "    X_test, y_test = get_scaled_xy(dataframe=test_df)\n",
        "\n",
        "    #Unsupervised\n",
        "    df = get_oversampled_df(X,y)\n",
        "    #base_probability = get_base_prob(dataframe=df)\n",
        "    X, y = get_scaled_xy(dataframe=df)\n",
        "    \n",
        "    EP, bestalgo, summary = get_EP_results(K_Means_nclusters=K_Means_nclusters,Mean_Shift_min_df_len=Mean_Shift_min_df_len,base_test_prob=base_test_probability,\\\n",
        "                                           X_train=X_train, y_train=y_train,X_test=X_test, y_test=y_test,train_date=train_date,test_date=test_date)\n",
        "    store_results(result_to_store=EP,resultdict=result2,train_date=train_date,test_date=test_date,hurdle=hurdle)\n",
        "    #-----End of program-----\n",
        "\n",
        "end = timer()\n",
        "print (end-start)\n",
        "\n",
        "result2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "152.81782761200003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'100%//2011-06-30//2012-06-30': {'DT': 0.03,\n",
              "  'KMeans': 0.12,\n",
              "  'KNN': 0.07,\n",
              "  'RF': 0.08,\n",
              "  'SVM': 0.02,\n",
              "  'base_test_prob': 0.38},\n",
              " '100%//2011-06-30//2013-06-30': {'DT': 0.01,\n",
              "  'KMeans': -0.29,\n",
              "  'KNN': 0.04,\n",
              "  'RF': 0.01,\n",
              "  'SVM': 0.01,\n",
              "  'base_test_prob': 0.29},\n",
              " '100%//2011-06-30//2014-06-30': {'DT': 0.0,\n",
              "  'KMeans': -0.19,\n",
              "  'KNN': 0.02,\n",
              "  'RF': -0.0,\n",
              "  'SVM': 0.01,\n",
              "  'base_test_prob': 0.19},\n",
              " '200%//2011-06-30//2012-06-30': {'DT': 0.06,\n",
              "  'KMeans': 0.37,\n",
              "  'KNN': 0.06,\n",
              "  'RF': 0.11,\n",
              "  'SVM': 0.04,\n",
              "  'base_test_prob': 0.13},\n",
              " '200%//2011-06-30//2013-06-30': {'DT': 0.0,\n",
              "  'KMeans': -0.09,\n",
              "  'KNN': 0.02,\n",
              "  'RF': 0.03,\n",
              "  'SVM': 0.02,\n",
              "  'base_test_prob': 0.09},\n",
              " '200%//2011-06-30//2014-06-30': {'DT': -0.01,\n",
              "  'KMeans': -0.06,\n",
              "  'KNN': -0.01,\n",
              "  'RF': -0.0,\n",
              "  'SVM': 0.01,\n",
              "  'base_test_prob': 0.06},\n",
              " '300%//2011-06-30//2012-06-30': {'DT': 0.03,\n",
              "  'KMeans': 0.45,\n",
              "  'KNN': 0.03,\n",
              "  'RF': 0.08,\n",
              "  'SVM': 0.05,\n",
              "  'base_test_prob': 0.05},\n",
              " '300%//2011-06-30//2013-06-30': {'DT': 0.02,\n",
              "  'KMeans': -0.04,\n",
              "  'KNN': -0.01,\n",
              "  'RF': 0.04,\n",
              "  'SVM': 0.02,\n",
              "  'base_test_prob': 0.04},\n",
              " '300%//2011-06-30//2014-06-30': {'DT': 0.01,\n",
              "  'KMeans': -0.03,\n",
              "  'KNN': -0.01,\n",
              "  'RF': 0.02,\n",
              "  'SVM': 0.01,\n",
              "  'base_test_prob': 0.03},\n",
              " '400%//2011-06-30//2012-06-30': {'DT': 0.02,\n",
              "  'KMeans': 0.48,\n",
              "  'KNN': 0.03,\n",
              "  'RF': 0.29,\n",
              "  'SVM': 0.02,\n",
              "  'base_test_prob': 0.02},\n",
              " '400%//2011-06-30//2013-06-30': {'DT': -0.02,\n",
              "  'KMeans': -0.02,\n",
              "  'KNN': -0.0,\n",
              "  'RF': 0.04,\n",
              "  'SVM': 0.01,\n",
              "  'base_test_prob': 0.02},\n",
              " '400%//2011-06-30//2014-06-30': {'DT': 0.01,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': 0.01,\n",
              "  'RF': 0.02,\n",
              "  'SVM': 0.02,\n",
              "  'base_test_prob': 0.01},\n",
              " '500%//2011-06-30//2012-06-30': {'DT': 0.01,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': 0.01,\n",
              "  'RF': 0.03,\n",
              "  'SVM': 0.01,\n",
              "  'base_test_prob': 0.01},\n",
              " '500%//2011-06-30//2013-06-30': {'DT': 0.02,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': 0.02,\n",
              "  'RF': 0.03,\n",
              "  'SVM': 0.01,\n",
              "  'base_test_prob': 0.01},\n",
              " '500%//2011-06-30//2014-06-30': {'DT': 0.01,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': 0.01,\n",
              "  'RF': 0.01,\n",
              "  'SVM': 0.0,\n",
              "  'base_test_prob': 0.01}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXrVpPnDL3tP"
      },
      "source": [
        "# Model Speed Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v63rbva9eCWO"
      },
      "source": [
        "## Model Speed Tester (MULTIPROCESSING)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5sMN9xm5aAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c8e88f8-3878-4a4a-c8a1-eaf7d77480ff"
      },
      "source": [
        "def test(hurdle,datepair,result):\n",
        "    #Setting of parameters\n",
        "    hurdle = hurdle\n",
        "    train_date = datepair[0]\n",
        "    test_date = datepair[1]\n",
        "    K_Means_nclusters = 2\n",
        "    Mean_Shift_min_df_len = 0.1\n",
        "\n",
        "    #-----Start main program-----\n",
        "    df = get_df(PATH)\n",
        "    df = df.loc[(df[\"As of date\"] == train_date)|(df[\"As of date\"] == test_date)]\n",
        "    add_hurdle_col(dataframe=df,hurdle=hurdle)\n",
        "    df = drop_useless_cols(dataframe=df)\n",
        "    clean_div_yield_col(dataframe=df)\n",
        "    clean_KMB_all_cols(dataframe=df)\n",
        "    #-----Start of ML-----\n",
        "    #Get X, y as individual dataframes\n",
        "    X, y = get_xy(dataframe=df)\n",
        "    X_train, y_train = get_xy(dataframe=df.loc[(df[\"As of date\"] == train_date)])\n",
        "    X_test, y_test = get_xy(dataframe=df.loc[(df[\"As of date\"] == test_date)])\n",
        "    #Supervised train\n",
        "    train_df = join_df(X_train,y_train)\n",
        "    X_train, y_train = get_scaled_xy(dataframe=train_df)\n",
        "    #Supervised test\n",
        "    test_df = join_df(X_test,y_test)\n",
        "    base_test_probability = get_base_prob(dataframe=test_df)\n",
        "    X_test, y_test = get_scaled_xy(dataframe=test_df)\n",
        "    #Unsupervised\n",
        "    df = join_df(X,y)\n",
        "    #base_probability = get_base_prob(dataframe=df)\n",
        "    X, y = get_scaled_xy(dataframe=df)\n",
        "    \n",
        "    EP, bestalgo, summary = get_EP_results(K_Means_nclusters=K_Means_nclusters,Mean_Shift_min_df_len=Mean_Shift_min_df_len,base_test_prob=base_test_probability,\\\n",
        "                                           X_train=X_train, y_train=y_train,X_test=X_test, y_test=y_test,train_date=train_date,test_date=test_date)\n",
        "    store_results(result_to_store=EP,resultdict=result,train_date=train_date,test_date=test_date,hurdle=hurdle)\n",
        "    #-----End of program-----\n",
        "\n",
        "PATH = '/content/drive/My Drive/YOUR_PATH_TO_DATA'\n",
        "\n",
        "#Lists to iterate over\n",
        "datepairs = [['2010-06-30','2011-06-30'],['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]\n",
        "#datepairs = [['2011-06-30','2012-06-30'],['2011-06-30','2013-06-30'],['2011-06-30','2014-06-30']]\n",
        "hurdlelist = [1,2,3,4,5] # >x*100% returns in the forward 5Y period\n",
        "\n",
        "start = timer()\n",
        "import multiprocessing as mp\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    manager = mp.Manager()\n",
        "    result3 = manager.dict()\n",
        "    jobs = []\n",
        "    for hurdle in hurdlelist:\n",
        "      for datepair in datepairs:\n",
        "        p = mp.Process(target=test, args=(hurdle,datepair,result3))\n",
        "        jobs.append(p)\n",
        "        p.start()\n",
        "\n",
        "    for proc in jobs:\n",
        "        proc.join()\n",
        "\n",
        "end = timer()\n",
        "print (end-start)\n",
        "result3 = dict(result3)\n",
        "result3\n",
        "'''\n",
        "import cProfile, pstats, io\n",
        "pr = cProfile.Profile()\n",
        "pr.enable()\n",
        "###############################\n",
        "test(1,['2011-06-30','2012-06-30'],result3)\n",
        "###############################\n",
        "pr.disable()\n",
        "s = io.StringIO()\n",
        "sortby = 'cumulative'\n",
        "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "ps.print_stats()\n",
        "print(s.getvalue())\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process Process-2:\n",
            "Traceback (most recent call last):\n",
            "Process Process-3:\n",
            "Process Process-5:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "Process Process-4:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Process Process-7:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "Process Process-6:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "Process Process-8:\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Process Process-9:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "Process Process-10:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "Traceback (most recent call last):\n",
            "Process Process-11:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "Traceback (most recent call last):\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "Process Process-12:\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "Traceback (most recent call last):\n",
            "Process Process-13:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "Process Process-14:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "Process Process-15:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "Process Process-16:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Process Process-17:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "Process Process-18:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Process Process-19:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Process Process-20:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "Process Process-21:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"<ipython-input-10-92fb488df4f0>\", line 10, in test\n",
            "    df = get_df(PATH)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"<ipython-input-3-bbbebad92957>\", line 2, in get_df\n",
            "    return pd.read_excel(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 304, in read_excel\n",
            "    io = ExcelFile(io, engine=engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 867, in __init__\n",
            "    self._reader = self._engines[engine](self._io)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 22, in __init__\n",
            "    super().__init__(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\", line 353, in __init__\n",
            "    self.book = self.load_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\", line 37, in load_workbook\n",
            "    return open_workbook(filepath_or_buffer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/US SC DATA.xlsx'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6081199160000779\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nimport cProfile, pstats, io\\npr = cProfile.Profile()\\npr.enable()\\n###############################\\ntest(1,['2011-06-30','2012-06-30'],result3)\\n###############################\\npr.disable()\\ns = io.StringIO()\\nsortby = 'cumulative'\\nps = pstats.Stats(pr, stream=s).sort_stats(sortby)\\nps.print_stats()\\nprint(s.getvalue())\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBY0g6A6eK72"
      },
      "source": [
        "## Model Speed Tester 2 (CONCURRENT FUTURES)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQglwcKY77Mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b8a090c-4455-43af-c71e-848ea71d588b"
      },
      "source": [
        "def test(hurdle,datepair,result):\n",
        "    #Setting of parameters\n",
        "    #hurdle = hurdle\n",
        "    train_date = datepair[0]\n",
        "    test_date = datepair[1]\n",
        "    K_Means_nclusters = 2\n",
        "    Mean_Shift_min_df_len = 0.1\n",
        "\n",
        "    #-----Start main program-----\n",
        "    df = get_df(PATH)\n",
        "    df = df.loc[(df[\"As of date\"] == train_date)|(df[\"As of date\"] == test_date)]\n",
        "    add_hurdle_col(dataframe=df,hurdle=hurdle)\n",
        "    df = drop_useless_cols(dataframe=df)\n",
        "    clean_div_yield_col(dataframe=df)\n",
        "    clean_KMB_all_cols(dataframe=df)\n",
        "    #-----Start of ML-----\n",
        "    #Get X, y as individual dataframes\n",
        "    X, y = get_xy(dataframe=df)\n",
        "    X_train, y_train = get_xy(dataframe=df.loc[(df[\"As of date\"] == train_date)])\n",
        "    X_test, y_test = get_xy(dataframe=df.loc[(df[\"As of date\"] == test_date)])\n",
        "    #Supervised train\n",
        "    train_df = join_df(X_train,y_train)\n",
        "    X_train, y_train = get_scaled_xy(dataframe=train_df)\n",
        "    #Supervised test\n",
        "    test_df = join_df(X_test,y_test)\n",
        "    base_test_probability = get_base_prob(dataframe=test_df)\n",
        "    X_test, y_test = get_scaled_xy(dataframe=test_df)\n",
        "    #Unsupervised\n",
        "    df = join_df(X,y)\n",
        "    #base_probability = get_base_prob(dataframe=df)\n",
        "    X, y = get_scaled_xy(dataframe=df)\n",
        "    \n",
        "    EP, bestalgo, summary = get_EP_results(K_Means_nclusters=K_Means_nclusters,Mean_Shift_min_df_len=Mean_Shift_min_df_len,base_test_prob=base_test_probability,\\\n",
        "                                           X_train=X_train, y_train=y_train,X_test=X_test, y_test=y_test,train_date=train_date,test_date=test_date)\n",
        "    store_results(result_to_store=EP,resultdict=result,train_date=train_date,test_date=test_date,hurdle=hurdle)\n",
        "    title = f'{hurdle*100}%//{train_date}//{test_date}'\n",
        "    return title, EP\n",
        "    #-----End of program-----\n",
        "    \n",
        "import concurrent.futures as cf\n",
        "from itertools import repeat\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def main(hurdlelist,datepairs,result):\n",
        "    with cf.ProcessPoolExecutor() as executor:#ThreadPoolExecutor() as executor:\n",
        "      x = [executor.submit(test,x,y,z) for x,y,z in zip(hurdlelist,datepairs,repeat(result))]\n",
        "      for i in cf.as_completed(x):\n",
        "            k, v = i.result()\n",
        "            result4[k] = v #result or result4?\n",
        "\n",
        "\n",
        "start = timer()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  PATH = '/content/drive/My Drive/YOUR_PATH_TO_DATA'\n",
        "  #args = [(x,y,result4) for x in hurdlelist for y in datepairs]\n",
        "  #Lists to iterate over\n",
        "  #datepairs = [['2010-06-30','2011-06-30']]#,['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]\n",
        "  datepairs = [['2011-06-30','2012-06-30'],['2011-06-30','2013-06-30'],['2011-06-30','2014-06-30']]\n",
        "  hurdlelist = [1,2,3,4,5] # >x*100% returns in the forward 5Y period\n",
        "  datepairs2 = [['2010-06-30','2011-06-30'],['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]*5\n",
        "  hurdlelist2 = [1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5] # >x*100% returns in the forward 5Y period\n",
        "  \n",
        "  result4 = {}\n",
        "  main(hurdlelist2,datepairs2,result4)\n",
        "  '''\n",
        "  p = Pool(processes=20)\n",
        "  data = p.starmap(test, zip(hurdlelist2,datepairs2,repeat(result4)))\n",
        "  p.close()\n",
        "  result5 = dict(data)\n",
        "  '''\n",
        "end = timer()\n",
        "print (end-start)\n",
        "\n",
        "result4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "160.67076105500007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'100%//2010-06-30//2011-06-30': {'DT': 0.04,\n",
              "  'KMeans': -0.25,\n",
              "  'KNN': 0.04,\n",
              "  'RF': 0.07,\n",
              "  'SVM': -0.25,\n",
              "  'base_test_prob': 0.25},\n",
              " '100%//2011-06-30//2012-06-30': {'DT': 0.02,\n",
              "  'KMeans': 0.12,\n",
              "  'KNN': 0.02,\n",
              "  'RF': 0.15,\n",
              "  'SVM': -0.38,\n",
              "  'base_test_prob': 0.38},\n",
              " '100%//2012-06-30//2013-06-30': {'DT': 0.05,\n",
              "  'KMeans': -0.29,\n",
              "  'KNN': 0.06,\n",
              "  'RF': 0.14,\n",
              "  'SVM': -0.29,\n",
              "  'base_test_prob': 0.29},\n",
              " '100%//2013-06-30//2014-06-30': {'DT': 0.06,\n",
              "  'KMeans': -0.19,\n",
              "  'KNN': 0.08,\n",
              "  'RF': 0.22,\n",
              "  'SVM': -0.19,\n",
              "  'base_test_prob': 0.19},\n",
              " '200%//2010-06-30//2011-06-30': {'DT': 0.03,\n",
              "  'KMeans': -0.07,\n",
              "  'KNN': 0.03,\n",
              "  'RF': 0.08,\n",
              "  'SVM': -0.07,\n",
              "  'base_test_prob': 0.07},\n",
              " '200%//2011-06-30//2012-06-30': {'DT': 0.04,\n",
              "  'KMeans': 0.37,\n",
              "  'KNN': 0.12,\n",
              "  'RF': -0.13,\n",
              "  'SVM': -0.13,\n",
              "  'base_test_prob': 0.13},\n",
              " '200%//2012-06-30//2013-06-30': {'DT': 0.05,\n",
              "  'KMeans': -0.09,\n",
              "  'KNN': 0.09,\n",
              "  'RF': 0.16,\n",
              "  'SVM': -0.09,\n",
              "  'base_test_prob': 0.09},\n",
              " '200%//2013-06-30//2014-06-30': {'DT': 0.03,\n",
              "  'KMeans': -0.06,\n",
              "  'KNN': 0.06,\n",
              "  'RF': -0.06,\n",
              "  'SVM': -0.06,\n",
              "  'base_test_prob': 0.06},\n",
              " '300%//2010-06-30//2011-06-30': {'DT': 0.01,\n",
              "  'KMeans': -0.03,\n",
              "  'KNN': -0.03,\n",
              "  'RF': 0.22,\n",
              "  'SVM': -0.03,\n",
              "  'base_test_prob': 0.03},\n",
              " '300%//2011-06-30//2012-06-30': {'DT': 0.11,\n",
              "  'KMeans': -0.0,\n",
              "  'KNN': -0.05,\n",
              "  'RF': -0.05,\n",
              "  'SVM': -0.05,\n",
              "  'base_test_prob': 0.05},\n",
              " '300%//2012-06-30//2013-06-30': {'DT': 0.03,\n",
              "  'KMeans': -0.04,\n",
              "  'KNN': -0.04,\n",
              "  'RF': -0.04,\n",
              "  'SVM': -0.04,\n",
              "  'base_test_prob': 0.04},\n",
              " '300%//2013-06-30//2014-06-30': {'DT': 0.01,\n",
              "  'KMeans': -0.03,\n",
              "  'KNN': -0.03,\n",
              "  'RF': -0.03,\n",
              "  'SVM': -0.03,\n",
              "  'base_test_prob': 0.03},\n",
              " '400%//2010-06-30//2011-06-30': {'DT': 0.0,\n",
              "  'KMeans': -0.02,\n",
              "  'KNN': -0.02,\n",
              "  'RF': -0.02,\n",
              "  'SVM': -0.02,\n",
              "  'base_test_prob': 0.02},\n",
              " '400%//2011-06-30//2012-06-30': {'DT': 0.05,\n",
              "  'KMeans': 0.48,\n",
              "  'KNN': -0.02,\n",
              "  'RF': -0.02,\n",
              "  'SVM': -0.02,\n",
              "  'base_test_prob': 0.02},\n",
              " '400%//2012-06-30//2013-06-30': {'DT': -0.02,\n",
              "  'KMeans': -0.02,\n",
              "  'KNN': -0.02,\n",
              "  'RF': -0.02,\n",
              "  'SVM': -0.02,\n",
              "  'base_test_prob': 0.02},\n",
              " '400%//2013-06-30//2014-06-30': {'DT': -0.01,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': -0.01,\n",
              "  'RF': -0.01,\n",
              "  'SVM': -0.01,\n",
              "  'base_test_prob': 0.01},\n",
              " '500%//2010-06-30//2011-06-30': {'DT': 0.03,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': -0.01,\n",
              "  'RF': -0.01,\n",
              "  'SVM': -0.01,\n",
              "  'base_test_prob': 0.01},\n",
              " '500%//2011-06-30//2012-06-30': {'DT': -0.01,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': -0.01,\n",
              "  'RF': -0.01,\n",
              "  'SVM': -0.01,\n",
              "  'base_test_prob': 0.01},\n",
              " '500%//2012-06-30//2013-06-30': {'DT': -0.01,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': -0.01,\n",
              "  'RF': -0.01,\n",
              "  'SVM': -0.01,\n",
              "  'base_test_prob': 0.01},\n",
              " '500%//2013-06-30//2014-06-30': {'DT': -0.01,\n",
              "  'KMeans': -0.01,\n",
              "  'KNN': -0.01,\n",
              "  'RF': -0.01,\n",
              "  'SVM': -0.01,\n",
              "  'base_test_prob': 0.01}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtE1vjovuaMV"
      },
      "source": [
        "# Model Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTRNSg_OcEOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea66198-c1a0-486d-8020-75c0a5b23e52"
      },
      "source": [
        "from numpy import mean\n",
        "\n",
        "algoDT1 = []\n",
        "algoKNN1 = []\n",
        "algoRF1 = []\n",
        "algoSVM1 = []\n",
        "algoKMeans1 = []\n",
        "algoMeanShift1 = []\n",
        "\n",
        "for k,v in result3.items():\n",
        "  algoDT1.append(v['DT']) if v['DT'] != -v['base_test_prob'] else None\n",
        "  algoKNN1.append(v['KNN']) if v['KNN'] != -v['base_test_prob'] else None\n",
        "  algoRF1.append(v['RF']) if v['RF'] != -v['base_test_prob'] else None\n",
        "  algoSVM1.append(v['SVM']) if v['SVM'] != -v['base_test_prob'] else None\n",
        "  algoKMeans1.append(v['KMeans']) if v['KMeans'] != -v['base_test_prob'] else None\n",
        "\n",
        "algoDT2 = []\n",
        "algoKNN2 = []\n",
        "algoRF2 = []\n",
        "algoSVM2 = []\n",
        "algoKMeans2 = []\n",
        "algoMeanShift2 = []\n",
        "\n",
        "for k,v in result4.items():\n",
        "  algoDT2.append(v['DT']) if v['DT'] != -v['base_test_prob'] else None\n",
        "  algoKNN2.append(v['KNN']) if v['KNN'] != -v['base_test_prob'] else None\n",
        "  algoRF2.append(v['RF']) if v['RF'] != -v['base_test_prob'] else None\n",
        "  algoSVM2.append(v['SVM']) if v['SVM'] != -v['base_test_prob'] else None\n",
        "  algoKMeans2.append(v['KMeans']) if v['KMeans'] != -v['base_test_prob'] else None\n",
        "\n",
        "AVGdict = {\n",
        "    'AVGalgoDT1' : [mean(algoDT1),len(algoDT1)],\n",
        "    'AVGalgoKNN1' : [mean(algoKNN1),len(algoKNN1)],\n",
        "    'AVGalgoRF1' : [mean(algoRF1),len(algoRF1)],\n",
        "    'AVGalgoSVM1' : [mean(algoSVM1),len(algoSVM1)],\n",
        "    'AVGalgoKMeans1' : [mean(algoKMeans1),len(algoKMeans1)],\n",
        "    'AVGalgoDT2' : [mean(algoDT2),len(algoDT2)],\n",
        "    'AVGalgoKNN2' : [mean(algoKNN2),len(algoKNN2)],\n",
        "    'AVGalgoRF2' : [mean(algoRF2),len(algoRF2)],\n",
        "    'AVGalgoSVM2' : [mean(algoSVM2),len(algoSVM2)],\n",
        "    'AVGalgoKMeans2' : [mean(algoKMeans2),len(algoKMeans2)]}\n",
        "\n",
        "AVGdict = {k: [round(v[0],2),v[1]] for k, v in AVGdict.items()}\n",
        "\n",
        "listdict = {\n",
        "    'DT1' : [algoDT1,len(algoDT1)],\n",
        "    'KNN1' : [algoKNN1,len(algoKNN1)],\n",
        "    'RF1' : [algoRF1,len(algoRF1)],\n",
        "    'SVM1' : [algoSVM1,len(algoSVM1)],\n",
        "    'KMeans1' : [algoKMeans1,len(algoKMeans1)],\n",
        "    'DT2' : [algoDT2,len(algoDT2)],\n",
        "    'KNN2' : [algoKNN2,len(algoKNN2)],\n",
        "    'RF2' : [algoRF2,len(algoRF2)],\n",
        "    'SVM2' : [algoSVM2,len(algoSVM2)],\n",
        "    'KMeans2' : [algoKMeans2,len(algoKMeans2)]}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Notes:\n",
        "DT is good for a little additional pct over base prob\n",
        "X - KMeans is only good in 1 year, (not suitable for usage)\n",
        "KNN is good for hurdle=1,2, cannot predict above that\n",
        "RF is very predictive, but only gives predictions for a few periods\n",
        "X - SVM is bad\n",
        "RANK - RF, KNN, DT           X - KMeans, SVM\n",
        "'''\n",
        "AVGdict\n",
        "#listdict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AVGalgoDT1': [nan, 0],\n",
              " 'AVGalgoDT2': [0.04, 15],\n",
              " 'AVGalgoKMeans1': [nan, 0],\n",
              " 'AVGalgoKMeans2': [0.24, 4],\n",
              " 'AVGalgoKNN1': [nan, 0],\n",
              " 'AVGalgoKNN2': [0.06, 8],\n",
              " 'AVGalgoRF1': [nan, 0],\n",
              " 'AVGalgoRF2': [0.15, 7],\n",
              " 'AVGalgoSVM1': [nan, 0],\n",
              " 'AVGalgoSVM2': [nan, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf89QKGmkr2C"
      },
      "source": [
        "def generate_model_report(y_actual,y_predict):\n",
        "  print(f\"Accuracy:\\t {accuracy_score(y_actual,y_predict)}\" )\n",
        "  print(f\"Precision:\\t {precision_score(y_actual,y_predict)}\" )\n",
        "  print(f\"Recall:\\t\\t {recall_score(y_actual,y_predict)}\" )\n",
        "  print(f\"F1 Score:\\t {f1_score(y_actual,y_predict)}\" )\n",
        "  pass\n",
        "\n",
        "def generate_auc_roc_curve(clf, X_test):\n",
        "  y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
        "  fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba)\n",
        "  auc = roc_auc_score(y_test, y_pred_proba)\n",
        "  plt.plot(fpr,tpr,label=\"AUC ROC Curve with Area Under the curve =\"+str(auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA1SY1kbIM1q"
      },
      "source": [
        "#pd.crosstab(pd.Series(y_predict,name ='Predicted'), pd.Series(y_test, name ='Actual'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Rx7JfyZE3X"
      },
      "source": [
        "#generate_model_report(y_test,y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNENRV5iZmxV"
      },
      "source": [
        "#generate_auc_roc_curve(clf, X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1h6gQ47klm5"
      },
      "source": [
        "# Backtester (Individual algos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11NPcHZA0CZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a440500-2cbd-49f0-8a75-4ce5eaeb5c8d"
      },
      "source": [
        "import itertools\n",
        "#List for iteration\n",
        "PATH = '/content/drive/My Drive/YOUR_PATH_TO_DATA'\n",
        "#datepairs = ([f'{2000+i}-06-30',f'{2000+i+1}-06-30'] for i in range(14)) #2000 to 2014\n",
        "hurdlelist = (i for i in range(1,2)) # >x*100% returns in the forward 5Y period\n",
        "\n",
        "#List for iteration\n",
        "#datepairs = [['2010-06-30','2011-06-30'],['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]\n",
        "#hurdlelist = [1,2,3,4,5] # >x*100% returns in the forward 5Y period\n",
        "bt_result = {}\n",
        "\n",
        "for hurdle in hurdlelist:\n",
        "  datepairs = ([f'{2000+i}-06-30',f'{2000+i+1}-06-30'] for i in range(14)) #2000 to 2014\n",
        "  for datepair in datepairs:\n",
        "    #-----Setting Parameters-----\n",
        "    train_date = datepair[0]\n",
        "    test_date = datepair[1]\n",
        "    hurdle = hurdle\n",
        "    K_Means_nclusters = 2\n",
        "    Mean_Shift_min_df_len = 0.1\n",
        "    #-----Start main program-----\n",
        "    df = get_df(PATH)\n",
        "    df = df.loc[(df[\"As of date\"] == train_date)|(df[\"As of date\"] == test_date)]\n",
        "    add_hurdle_col(dataframe=df,hurdle=hurdle)\n",
        "    df = drop_useless_cols(dataframe=df)\n",
        "    clean_div_yield_col(dataframe=df)\n",
        "    clean_KMB_all_cols(dataframe=df)\n",
        "    #-----ADDITIONS-----\n",
        "    #df = df.loc[(df['5Y AVG P/E']!=-10000)&(df['5Y AVG P/FCF']!=-10000)] ##### remove negative 5y returns companies\n",
        "    #df.drop(['CAGR of Revenue:CQ T12M','Gr PoP of Avg Shares for EPS:Q','Gr PoP of Avg Shares for EPS:Q.1','Dvd Yld'], axis=1, inplace=True)\n",
        "    #-----END OF ADDITIONS-----\n",
        "    #-----Start of ML-----\n",
        "    #Get X, y as individual dataframes\n",
        "    X, y = get_xy(dataframe=df)\n",
        "    X_train, y_train = get_xy(dataframe=df.loc[(df[\"As of date\"] == train_date)])\n",
        "    X_test, y_test = get_xy(dataframe=df.loc[(df[\"As of date\"] == test_date)])\n",
        "    #Supervised train\n",
        "    train_df = join_df(X_train,y_train)\n",
        "    X_train, y_train = get_scaled_xy(dataframe=train_df)\n",
        "    #Supervised test\n",
        "    test_df = join_df(X_test,y_test)\n",
        "    base_test_probability = get_base_prob(dataframe=test_df)\n",
        "    X_test, y_test = get_scaled_xy(dataframe=test_df)\n",
        "    #Unsupervised\n",
        "    df2 = join_df(X,y)\n",
        "    #base_probability = get_base_prob(dataframe=df)\n",
        "    X, y = get_scaled_xy(dataframe=df2)\n",
        "    #-----End of data retrieval-----\n",
        "    #-----BACKTESTER-----\n",
        "    #print(f'Hurdle: {hurdle} // Train Date: {train_date} // Test Date: {test_date}')\n",
        "    run_result = {}\n",
        "    for i in range(10):\n",
        "      # Random Forest\n",
        "      clf = RandomForestClassifier(n_jobs=-1) #neighbors.KNeighborsClassifier() #DecisionTreeClassifier() #RandomForestClassifier(n_jobs=-1)\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_predict = clf.predict(X_test)\n",
        "      #print(precision_score(y_test,y_predict,zero_division=0))\n",
        "      #Precision x (hurdle+1) > 1\n",
        "      #print(precision_score(y_test,y_predict,zero_division=0)*(hurdle+1))\n",
        "      result = df[(df['As of date']==test_date)]\n",
        "      result.reset_index(inplace = True)\n",
        "      result = result.join(pd.DataFrame(y_predict))\n",
        "      result = result[(result[0] == 1)]\n",
        "      run_result[f'Run: {i}'] = round(result['Fwd 5Y Return'].mean()*100,0)\n",
        "    bt_result[f'Hurdle: {hurdle} // Train Date: {train_date} // Test Date: {test_date}'] = pd.Series([*run_result.values()]).mean()\n",
        "  print (f'Run: {hurdle}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMo4K_XfQ7cy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8afed466-c7e1-4d2f-8d49-d22a27928b8b"
      },
      "source": [
        "bt_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Hurdle: 1 // Train Date: 2000-06-30 // Test Date: 2001-06-30': 104.9,\n",
              " 'Hurdle: 1 // Train Date: 2001-06-30 // Test Date: 2002-06-30': 135.9,\n",
              " 'Hurdle: 1 // Train Date: 2002-06-30 // Test Date: 2003-06-30': 121.3,\n",
              " 'Hurdle: 1 // Train Date: 2003-06-30 // Test Date: 2004-06-30': 21.1,\n",
              " 'Hurdle: 1 // Train Date: 2004-06-30 // Test Date: 2005-06-30': -85.0,\n",
              " 'Hurdle: 1 // Train Date: 2005-06-30 // Test Date: 2006-06-30': 107.8,\n",
              " 'Hurdle: 1 // Train Date: 2006-06-30 // Test Date: 2007-06-30': 99.11111111111111,\n",
              " 'Hurdle: 1 // Train Date: 2007-06-30 // Test Date: 2008-06-30': 134.0,\n",
              " 'Hurdle: 1 // Train Date: 2008-06-30 // Test Date: 2009-06-30': 229.5,\n",
              " 'Hurdle: 1 // Train Date: 2009-06-30 // Test Date: 2010-06-30': 125.9,\n",
              " 'Hurdle: 1 // Train Date: 2010-06-30 // Test Date: 2011-06-30': 80.4,\n",
              " 'Hurdle: 1 // Train Date: 2011-06-30 // Test Date: 2012-06-30': 127.4,\n",
              " 'Hurdle: 1 // Train Date: 2012-06-30 // Test Date: 2013-06-30': 99.4,\n",
              " 'Hurdle: 1 // Train Date: 2013-06-30 // Test Date: 2014-06-30': 86.8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aB0FlUO_Wh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "ab54c79c-0e5f-4212-973b-8e66ae6b8bf2"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Market Cap</th>\n",
              "      <th>CAGR of Revenue:CQ T12M</th>\n",
              "      <th>Gr PoP of Avg Shares for EPS:Q</th>\n",
              "      <th>Gr PoP of Avg Shares for EPS:Q.1</th>\n",
              "      <th>5Y AVG P/E</th>\n",
              "      <th>5Y AVG P/FCF</th>\n",
              "      <th>Dvd Yld</th>\n",
              "      <th>Fwd 5Y Return</th>\n",
              "      <th>As of date</th>\n",
              "      <th>Y</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1879</td>\n",
              "      <td>9.680000e+09</td>\n",
              "      <td>-1.19</td>\n",
              "      <td>33.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>23.44</td>\n",
              "      <td>-10000.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135590</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1890</td>\n",
              "      <td>9.460000e+09</td>\n",
              "      <td>167.96</td>\n",
              "      <td>69.88</td>\n",
              "      <td>23.08</td>\n",
              "      <td>-10000.00</td>\n",
              "      <td>-10000.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.505315</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1896</td>\n",
              "      <td>9.360000e+09</td>\n",
              "      <td>-6.10</td>\n",
              "      <td>34.85</td>\n",
              "      <td>15.08</td>\n",
              "      <td>29.54</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.72</td>\n",
              "      <td>1.443848</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1907</td>\n",
              "      <td>9.110000e+09</td>\n",
              "      <td>-6.02</td>\n",
              "      <td>20.81</td>\n",
              "      <td>-2.70</td>\n",
              "      <td>29.33</td>\n",
              "      <td>10.36</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.600057</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1910</td>\n",
              "      <td>8.950000e+09</td>\n",
              "      <td>1.04</td>\n",
              "      <td>-21.58</td>\n",
              "      <td>-3.69</td>\n",
              "      <td>14.11</td>\n",
              "      <td>8.46</td>\n",
              "      <td>1.63</td>\n",
              "      <td>0.076340</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1683</th>\n",
              "      <td>3553</td>\n",
              "      <td>3.577400e+08</td>\n",
              "      <td>4.54</td>\n",
              "      <td>19.41</td>\n",
              "      <td>4.25</td>\n",
              "      <td>17.27</td>\n",
              "      <td>12.99</td>\n",
              "      <td>2.25</td>\n",
              "      <td>0.843310</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1685</th>\n",
              "      <td>3555</td>\n",
              "      <td>3.567600e+08</td>\n",
              "      <td>2.26</td>\n",
              "      <td>52.17</td>\n",
              "      <td>8.38</td>\n",
              "      <td>31.59</td>\n",
              "      <td>9.62</td>\n",
              "      <td>1.16</td>\n",
              "      <td>1.438432</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1687</th>\n",
              "      <td>3557</td>\n",
              "      <td>3.563000e+08</td>\n",
              "      <td>8.51</td>\n",
              "      <td>-24.16</td>\n",
              "      <td>-3.96</td>\n",
              "      <td>10.06</td>\n",
              "      <td>10.97</td>\n",
              "      <td>5.40</td>\n",
              "      <td>1.037845</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1731</th>\n",
              "      <td>3601</td>\n",
              "      <td>3.312200e+08</td>\n",
              "      <td>35.80</td>\n",
              "      <td>41.56</td>\n",
              "      <td>2.15</td>\n",
              "      <td>21.81</td>\n",
              "      <td>26.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.130724</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1738</th>\n",
              "      <td>3608</td>\n",
              "      <td>3.279500e+08</td>\n",
              "      <td>3.34</td>\n",
              "      <td>374.65</td>\n",
              "      <td>1.43</td>\n",
              "      <td>41.00</td>\n",
              "      <td>7.22</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.791499</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>92 rows  12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index    Market Cap  CAGR of Revenue:CQ T12M  ...  As of date    Y    0\n",
              "9      1879  9.680000e+09                    -1.19  ...  2014-06-30  0.0  1.0\n",
              "20     1890  9.460000e+09                   167.96  ...  2014-06-30  0.0  1.0\n",
              "26     1896  9.360000e+09                    -6.10  ...  2014-06-30  1.0  1.0\n",
              "37     1907  9.110000e+09                    -6.02  ...  2014-06-30  0.0  1.0\n",
              "40     1910  8.950000e+09                     1.04  ...  2014-06-30  0.0  1.0\n",
              "...     ...           ...                      ...  ...         ...  ...  ...\n",
              "1683   3553  3.577400e+08                     4.54  ...  2014-06-30  0.0  1.0\n",
              "1685   3555  3.567600e+08                     2.26  ...  2014-06-30  1.0  1.0\n",
              "1687   3557  3.563000e+08                     8.51  ...  2014-06-30  1.0  1.0\n",
              "1731   3601  3.312200e+08                    35.80  ...  2014-06-30  1.0  1.0\n",
              "1738   3608  3.279500e+08                     3.34  ...  2014-06-30  0.0  1.0\n",
              "\n",
              "[92 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6EEkkwouhi7"
      },
      "source": [
        "# Future improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxCU7eXZcQEh"
      },
      "source": [
        "# Normalize with max(\"x/x(absmax)\"), l1(\"x/sum(x)\") , l2(euclidean dist)\n",
        "# Optimize with numba, cprofile, multiprocessing etc\n",
        "# Binning of returns?\n",
        "# https://www.oreilly.com/library/view/machine-learning-with/9781491989371/ch04.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1VYaoDAlNp4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3426b456-6ba2-43ef-9a57-2b005b9b6c6f"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VoPs8oWU5_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e18bb64-acce-4671-9846-caf9e29b1582"
      },
      "source": [
        "import multiprocessing as mp\n",
        "print(\"Number of processors: \", mp.cpu_count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of processors:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6kXDlCmk2di"
      },
      "source": [
        "# Other checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgKlsn3MbN4Y"
      },
      "source": [
        "#Check for unbalanced data\n",
        "unique_classes = list(os_df['Y'].unique())\n",
        "print(unique_classes)\n",
        "    \n",
        "out_dict = {}\n",
        "for classes in unique_classes:\n",
        "    out_dict[classes] = os_df.shape[0]/((os_df.loc[os_df['Y'] == classes].shape[0])\n",
        "                                     *len(unique_classes))\n",
        "print(out_dict)\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#Before resampling\n",
        "print(Counter(y))\n",
        "\n",
        "#After resampling\n",
        "X_res, y_res = SMOTE(random_state=0).fit_resample(X, y)\n",
        "print(Counter(y_res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rQqmjQt-zEd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpYMY3NKVKkk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}