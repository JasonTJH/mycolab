{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "USEquityML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonTJH/mycolab/blob/main/USEquityML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaHScvdFuGtl"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNxWdwuA6AER"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHTRxnoQIqPe"
      },
      "source": [
        "# Visualization\n",
        "#from openpyxl.workbook import Workbook\n",
        "#from openpyxl import load_workbook\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Machine Learning\n",
        "from sklearn import preprocessing, neighbors, svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.cluster import KMeans, MeanShift\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# For oversampling to balance the dataset\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# Results Analysis\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score, roc_curve\n",
        "#Model weight manipulation (may cause overfitting though)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pylab import rcParams\n",
        "#\n",
        "from timeit import default_timer as timer\n",
        "sns.set()\n",
        "\n",
        "#from numba import jit, njit\n",
        "#GPU VERSIONS\n",
        "#import cupy as np\n",
        "#import cudf as pd\n",
        "#import cuml as sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GSi43LCIqQJ"
      },
      "source": [
        "def get_df(path: str):\n",
        "  return pd.read_excel(path)\n",
        "\n",
        "def add_hurdle_col(dataframe,hurdle):\n",
        "  #Add new col\n",
        "  dataframe.loc[dataframe['Fwd 5Y Return'] >= hurdle, 'Y'] = 1\n",
        "  dataframe.loc[dataframe['Fwd 5Y Return'] < hurdle, 'Y'] = 0\n",
        "\n",
        "def get_base_prob(dataframe):\n",
        "  base_probability = round(len(dataframe[(dataframe['Y']==1)])/len(dataframe),2)\n",
        "  return base_probability\n",
        "\n",
        "def drop_useless_cols(dataframe):\n",
        "  # Drop useless columns\n",
        "  dataframe = dataframe.drop(['Ticker','Name'],axis=1)\n",
        "  return dataframe\n",
        "\n",
        "def clean_div_yield_col(dataframe):\n",
        "  # Clean dividend yield column\n",
        "  dataframe['Dvd Yld'] = dataframe['Dvd Yld'].str[:-1].astype(float)\n",
        "\n",
        "def clean_KMB_all_cols(dataframe):\n",
        "  # Clean K, M, B from all columns\n",
        "  repl_dict = {'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9'}\n",
        "  for col in dataframe:\n",
        "      try:\n",
        "          dataframe[col] = dataframe[col].replace(repl_dict, regex=True).map(pd.eval).astype(float)\n",
        "      except:\n",
        "          None\n",
        "\n",
        "def get_xy(dataframe):\n",
        "  #Data Selection/Preparation (X and y are dataframes)\n",
        "  X = dataframe.drop(['Fwd 5Y Return','Y','As of date'],1)\n",
        "  y = dataframe['Y'].to_frame()\n",
        "  return X,y\n",
        "\n",
        "def get_oversampled_df(X,y):\n",
        "  #Data Oversampling for balancing\n",
        "  X_resampled, y_resampled = SMOTE(random_state=0).fit_resample(X,y.values.ravel())\n",
        "  #Create oversampled df\n",
        "  oversampled_df = pd.DataFrame(X_resampled, columns=X.columns).join(pd.DataFrame(y_resampled, columns=y.columns))\n",
        "  return oversampled_df\n",
        "\n",
        "def join_df(X,y):\n",
        "  #Create oversampled df\n",
        "  new_df = X.join(y)\n",
        "  return new_df\n",
        "\n",
        "def get_scaled_xy(dataframe):\n",
        "  #Change X and y to np arrays for input into models\n",
        "  X = np.array(dataframe.drop(['Y'],1))\n",
        "  y = np.array(dataframe['Y'])\n",
        "  #Data Scaling\n",
        "  scaler = RobustScaler(quantile_range=(5, 95))\n",
        "  X = scaler.fit_transform(X)\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVSkqgUTIqRZ"
      },
      "source": [
        "def get_EP_results(K_Means_nclusters:int,Mean_Shift_min_df_len:float,base_test_prob:float,X_train, y_train,X_test, y_test,train_date,test_date):\n",
        "\n",
        "  EP = {'DT' : DT(X_train, y_train,X_test, y_test)-base_test_prob,\n",
        "        'KNN' : KNN(X_train, y_train,X_test, y_test)-base_test_prob,\n",
        "        'RF' : RF(X_train, y_train,X_test, y_test)-base_test_prob,\n",
        "        'SVM' : SVM(X_train, y_train,X_test, y_test)-base_test_prob,\n",
        "        'KMeans' : K_Means(K_Means_nclusters,X_train, y_train,X_test, y_test)-base_test_prob}#,\n",
        "        #'MeanShift' : Mean_Shift(df,Mean_Shift_min_df_len)-base_prob}\n",
        "  \n",
        "  EP = {k: round(v,2) for k, v in EP.items()}\n",
        "  \n",
        "  x = (f\"Decision Tree:\\t\\t{EP['DT']}\\\n",
        "      \\nK Nearest Neighbors:\\t{EP['KNN']}\\\n",
        "      \\nRandom Forest:\\t\\t{EP['RF']}\\\n",
        "      \\nSupport Vector Machine:\\t{EP['SVM']}\\\n",
        "      \\nK Means Clustering:\\t{EP['KMeans']})\")\n",
        "      #\\nMean Shift:\\t\\t{EP['MeanShift']}\")\n",
        "\n",
        "  bestalgo = {'Algo':max(EP,key=EP.get),\n",
        "            'ExProb':max(EP.values()),\n",
        "            'BaseProb':base_prob if max(EP,key=EP.get) == 'MeanShift' else base_test_prob,\n",
        "            'Precision':round(max(EP.values()) + (base_prob if max(EP,key=EP.get) == 'MeanShift' else base_test_prob),2),\n",
        "            'Traindate':train_date,\n",
        "            'Testdate':test_date}\n",
        "      \n",
        "  y = (f\"The Best Algorithm:\\t{bestalgo['Algo']}\\\n",
        "      \\nExcess probability:\\t{bestalgo['ExProb']}\\\n",
        "      \\nBase probability:\\t{bestalgo['BaseProb']}\\\n",
        "      \\n\\\n",
        "      \\nTrain date:\\t\\t{bestalgo['Traindate']}\\\n",
        "      \\nTest date:\\t\\t{bestalgo['Testdate']}\")\n",
        "  \n",
        "  #EP['base_prob'] = base_prob\n",
        "  EP['base_test_prob'] = base_test_prob\n",
        "  \n",
        "  return EP, bestalgo, f\"Excess Probabilities\\n\\n{x}\\n\\n{y}\"\n",
        "\n",
        "def store_results(result_to_store,resultdict,train_date,test_date,hurdle):\n",
        "  resultdict[f'{hurdle*100}%//{train_date}//{test_date}'] = result_to_store"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E6R7RYevEfL"
      },
      "source": [
        "# Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1nFDA82IqQq"
      },
      "source": [
        "def DT(X_train, y_train,X_test, y_test):\n",
        "  # Decision Tree\n",
        "  clf = DecisionTreeClassifier()\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_predict = clf.predict(X_test)\n",
        "  return precision_score(y_test,y_predict,zero_division=0)\n",
        "\n",
        "def KNN(X_train, y_train,X_test, y_test):\n",
        "  # K Nearest Neighbors\n",
        "  clf = neighbors.KNeighborsClassifier()\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_predict = clf.predict(X_test)\n",
        "  return precision_score(y_test,y_predict,zero_division=0)\n",
        "\n",
        "def RF(X_train, y_train,X_test, y_test):\n",
        "  # Random Forest\n",
        "  clf = RandomForestClassifier()\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_predict = clf.predict(X_test)\n",
        "  return precision_score(y_test,y_predict,zero_division=0)\n",
        "\n",
        "def SVM(X_train, y_train,X_test, y_test):\n",
        "  # Support Vector Machine\n",
        "  clf = svm.SVC(kernel='rbf', C=1)\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_predict = clf.predict(X_test)\n",
        "  return precision_score(y_test,y_predict,zero_division=0)\n",
        "\n",
        "def K_Means(num_clusters,X_train, y_train,X_test, y_test):\n",
        "  # K Means Clustering (unsupervised)\n",
        "  clf = KMeans(n_clusters=num_clusters)\n",
        "  clf.fit(X_train)\n",
        "  postivepred = 0\n",
        "  correct_pos = 0\n",
        "  for i in range(len(X_test)):\n",
        "      predict_me = np.array(X_test[i].astype(float))\n",
        "      predict_me = predict_me.reshape(-1,len(predict_me))\n",
        "      prediction = clf.predict(predict_me)\n",
        "      if prediction[0] == np.ones(1):\n",
        "        postivepred+=1\n",
        "        if prediction[0] == y_test[i]:\n",
        "          correct_pos+=1\n",
        "  precision = correct_pos/postivepred if postivepred > 0 else 0\n",
        "  return precision\n",
        "\n",
        "def Mean_Shift(dataframe,min_df_len,X_train, y_train,X_test, y_test):\n",
        "  # Means Shift (unsupervised)\n",
        "  clf = MeanShift()\n",
        "  clf.fit(X)\n",
        "  labels = clf.labels_\n",
        "  cluster_centers = clf.cluster_centers_\n",
        "  dataframe['cluster_group'] = labels\n",
        "  n_clusters_= len(np.unique(labels))\n",
        "  correct_rates = {}\n",
        "\n",
        "  for i in range(n_clusters_):\n",
        "      temp_df = dataframe.loc[(dataframe[\"cluster_group\"] == float(i))].copy()\n",
        "      correct_cluster = temp_df.loc[(temp_df[\"Y\"] == 1)].copy()\n",
        "      correct_rate = len(correct_cluster)/len(temp_df)\n",
        "      if len(temp_df)>min_df_len*len(dataframe):\n",
        "          correct_rates[i]= correct_rate\n",
        "  return max(correct_rates.values())\n",
        "  # MeanShift algo returns the cluster number/key i/o underlying binary outcomes.\n",
        "  # Already using precision (we are choosing the cluster with best precision)\n",
        "  # This algorithm is very slow...."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww7a1X_ZuWW5"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCwem2xgzX9b"
      },
      "source": [
        "## Model for normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-ZZUDlBnOek"
      },
      "source": [
        "start = timer()\n",
        "PATH = '/content/drive/My Drive/YOUR_PATH_TO_DATA'\n",
        "result1 = {}\n",
        "\n",
        "#Lists to iterate over\n",
        "#datepairs = [['2010-06-30','2011-06-30']]#,['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]\n",
        "datepairs = [['2011-06-30','2012-06-30'],['2011-06-30','2013-06-30'],['2011-06-30','2014-06-30']]\n",
        "hurdlelist = [1,2,3,4,5] # >x*100% returns in the forward 5Y period\n",
        "\n",
        "for hurdle in hurdlelist:\n",
        "  for datepair in datepairs:\n",
        "    #Setting of parameters\n",
        "    hurdle = hurdle\n",
        "    train_date = datepair[0]\n",
        "    test_date = datepair[1]\n",
        "    K_Means_nclusters = 2\n",
        "    Mean_Shift_min_df_len = 0.1\n",
        "\n",
        "    #-----Start main program-----\n",
        "    df = get_df(PATH)\n",
        "    df = df.loc[(df[\"As of date\"] == train_date)|(df[\"As of date\"] == test_date)]\n",
        "    add_hurdle_col(dataframe=df,hurdle=hurdle)\n",
        "    df = drop_useless_cols(dataframe=df)\n",
        "    clean_div_yield_col(dataframe=df)\n",
        "    clean_KMB_all_cols(dataframe=df)\n",
        "    #-----Start of ML-----\n",
        "    #Get X, y as individual dataframes\n",
        "    X, y = get_xy(dataframe=df)\n",
        "    X_train, y_train = get_xy(dataframe=df.loc[(df[\"As of date\"] == train_date)])\n",
        "    X_test, y_test = get_xy(dataframe=df.loc[(df[\"As of date\"] == test_date)])\n",
        "\n",
        "    train_df = join_df(X_train,y_train)\n",
        "    X_train, y_train = get_scaled_xy(dataframe=train_df)\n",
        "    \n",
        "    #Supervised test\n",
        "    test_df = join_df(X_test,y_test)\n",
        "    base_test_probability = get_base_prob(dataframe=test_df)\n",
        "    X_test, y_test = get_scaled_xy(dataframe=test_df)\n",
        "\n",
        "    df = join_df(X,y)\n",
        "    #base_probability = get_base_prob(dataframe=df)\n",
        "    X, y = get_scaled_xy(dataframe=df)\n",
        "    \n",
        "    EP, bestalgo, summary = get_EP_results(K_Means_nclusters=K_Means_nclusters,Mean_Shift_min_df_len=Mean_Shift_min_df_len,base_test_prob=base_test_probability,\\\n",
        "                                           X_train=X_train, y_train=y_train,X_test=X_test, y_test=y_test,train_date=train_date,test_date=test_date)\n",
        "    store_results(result_to_store=EP,resultdict=result1,train_date=train_date,test_date=test_date,hurdle=hurdle)\n",
        "    #-----End of program-----\n",
        "\n",
        "end = timer()\n",
        "print (end-start)\n",
        "\n",
        "result1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkP8m6vjzSA1"
      },
      "source": [
        "## Model for oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJsR4GEzzInJ"
      },
      "source": [
        "start = timer()\n",
        "PATH = '/content/drive/My Drive/YOUR_PATH_TO_DATA'\n",
        "result2 = {}\n",
        "\n",
        "#Lists to iterate over\n",
        "#datepairs = [['2010-06-30','2011-06-30']]#,['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]\n",
        "datepairs = [['2011-06-30','2012-06-30'],['2011-06-30','2013-06-30'],['2011-06-30','2014-06-30']]\n",
        "hurdlelist = [1,2,3,4,5] # >x*100% returns in the forward 5Y period\n",
        "\n",
        "for hurdle in hurdlelist:\n",
        "  for datepair in datepairs:\n",
        "    #Setting of parameters\n",
        "    hurdle = hurdle\n",
        "    train_date = datepair[0]\n",
        "    test_date = datepair[1]\n",
        "    K_Means_nclusters = 2\n",
        "    Mean_Shift_min_df_len = 0.1\n",
        "\n",
        "    #-----Start main program-----\n",
        "    df = get_df(PATH)\n",
        "    df = df.loc[(df[\"As of date\"] == train_date)|(df[\"As of date\"] == test_date)]\n",
        "    add_hurdle_col(dataframe=df,hurdle=hurdle)\n",
        "    df = drop_useless_cols(dataframe=df)\n",
        "    clean_div_yield_col(dataframe=df)\n",
        "    clean_KMB_all_cols(dataframe=df)\n",
        "    #-----Start of ML-----\n",
        "    #Get X, y as individual dataframes\n",
        "    X, y = get_xy(dataframe=df)\n",
        "    X_train, y_train = get_xy(dataframe=df.loc[(df[\"As of date\"] == train_date)])\n",
        "    X_test, y_test = get_xy(dataframe=df.loc[(df[\"As of date\"] == test_date)])\n",
        "\n",
        "    #Supervised train\n",
        "    ostrain_df = get_oversampled_df(X_train,y_train)\n",
        "    X_train, y_train = get_scaled_xy(dataframe=ostrain_df)\n",
        "\n",
        "    #Supervised test\n",
        "    test_df = join_df(X_test,y_test)\n",
        "    base_test_probability = get_base_prob(dataframe=test_df)\n",
        "    X_test, y_test = get_scaled_xy(dataframe=test_df)\n",
        "\n",
        "    #Unsupervised\n",
        "    df = get_oversampled_df(X,y)\n",
        "    #base_probability = get_base_prob(dataframe=df)\n",
        "    X, y = get_scaled_xy(dataframe=df)\n",
        "    \n",
        "    EP, bestalgo, summary = get_EP_results(K_Means_nclusters=K_Means_nclusters,Mean_Shift_min_df_len=Mean_Shift_min_df_len,base_test_prob=base_test_probability,\\\n",
        "                                           X_train=X_train, y_train=y_train,X_test=X_test, y_test=y_test,train_date=train_date,test_date=test_date)\n",
        "    store_results(result_to_store=EP,resultdict=result2,train_date=train_date,test_date=test_date,hurdle=hurdle)\n",
        "    #-----End of program-----\n",
        "\n",
        "end = timer()\n",
        "print (end-start)\n",
        "\n",
        "result2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXrVpPnDL3tP"
      },
      "source": [
        "# Model Speed Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v63rbva9eCWO"
      },
      "source": [
        "## Model Speed Tester (MULTIPROCESSING)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5sMN9xm5aAX"
      },
      "source": [
        "def test(hurdle,datepair,result):\n",
        "    #Setting of parameters\n",
        "    hurdle = hurdle\n",
        "    train_date = datepair[0]\n",
        "    test_date = datepair[1]\n",
        "    K_Means_nclusters = 2\n",
        "    Mean_Shift_min_df_len = 0.1\n",
        "\n",
        "    #-----Start main program-----\n",
        "    df = get_df(PATH)\n",
        "    df = df.loc[(df[\"As of date\"] == train_date)|(df[\"As of date\"] == test_date)]\n",
        "    add_hurdle_col(dataframe=df,hurdle=hurdle)\n",
        "    df = drop_useless_cols(dataframe=df)\n",
        "    clean_div_yield_col(dataframe=df)\n",
        "    clean_KMB_all_cols(dataframe=df)\n",
        "    #-----Start of ML-----\n",
        "    #Get X, y as individual dataframes\n",
        "    X, y = get_xy(dataframe=df)\n",
        "    X_train, y_train = get_xy(dataframe=df.loc[(df[\"As of date\"] == train_date)])\n",
        "    X_test, y_test = get_xy(dataframe=df.loc[(df[\"As of date\"] == test_date)])\n",
        "    #Supervised train\n",
        "    train_df = join_df(X_train,y_train)\n",
        "    X_train, y_train = get_scaled_xy(dataframe=train_df)\n",
        "    #Supervised test\n",
        "    test_df = join_df(X_test,y_test)\n",
        "    base_test_probability = get_base_prob(dataframe=test_df)\n",
        "    X_test, y_test = get_scaled_xy(dataframe=test_df)\n",
        "    #Unsupervised\n",
        "    df = join_df(X,y)\n",
        "    #base_probability = get_base_prob(dataframe=df)\n",
        "    X, y = get_scaled_xy(dataframe=df)\n",
        "    \n",
        "    EP, bestalgo, summary = get_EP_results(K_Means_nclusters=K_Means_nclusters,Mean_Shift_min_df_len=Mean_Shift_min_df_len,base_test_prob=base_test_probability,\\\n",
        "                                           X_train=X_train, y_train=y_train,X_test=X_test, y_test=y_test,train_date=train_date,test_date=test_date)\n",
        "    store_results(result_to_store=EP,resultdict=result,train_date=train_date,test_date=test_date,hurdle=hurdle)\n",
        "    #-----End of program-----\n",
        "\n",
        "PATH = '/content/drive/My Drive/YOUR_PATH_TO_DATA'\n",
        "\n",
        "#Lists to iterate over\n",
        "datepairs = [['2010-06-30','2011-06-30'],['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]\n",
        "#datepairs = [['2011-06-30','2012-06-30'],['2011-06-30','2013-06-30'],['2011-06-30','2014-06-30']]\n",
        "hurdlelist = [1,2,3,4,5] # >x*100% returns in the forward 5Y period\n",
        "\n",
        "start = timer()\n",
        "import multiprocessing as mp\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    manager = mp.Manager()\n",
        "    result3 = manager.dict()\n",
        "    jobs = []\n",
        "    for hurdle in hurdlelist:\n",
        "      for datepair in datepairs:\n",
        "        p = mp.Process(target=test, args=(hurdle,datepair,result3))\n",
        "        jobs.append(p)\n",
        "        p.start()\n",
        "\n",
        "    for proc in jobs:\n",
        "        proc.join()\n",
        "\n",
        "end = timer()\n",
        "print (end-start)\n",
        "result3 = dict(result3)\n",
        "result3\n",
        "'''\n",
        "import cProfile, pstats, io\n",
        "pr = cProfile.Profile()\n",
        "pr.enable()\n",
        "###############################\n",
        "test(1,['2011-06-30','2012-06-30'],result3)\n",
        "###############################\n",
        "pr.disable()\n",
        "s = io.StringIO()\n",
        "sortby = 'cumulative'\n",
        "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "ps.print_stats()\n",
        "print(s.getvalue())\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBY0g6A6eK72"
      },
      "source": [
        "## Model Speed Tester 2 (CONCURRENT FUTURES)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQglwcKY77Mz"
      },
      "source": [
        "def test(hurdle,datepair,result):\n",
        "    #Setting of parameters\n",
        "    #hurdle = hurdle\n",
        "    train_date = datepair[0]\n",
        "    test_date = datepair[1]\n",
        "    K_Means_nclusters = 2\n",
        "    Mean_Shift_min_df_len = 0.1\n",
        "\n",
        "    #-----Start main program-----\n",
        "    df = get_df(PATH)\n",
        "    df = df.loc[(df[\"As of date\"] == train_date)|(df[\"As of date\"] == test_date)]\n",
        "    add_hurdle_col(dataframe=df,hurdle=hurdle)\n",
        "    df = drop_useless_cols(dataframe=df)\n",
        "    clean_div_yield_col(dataframe=df)\n",
        "    clean_KMB_all_cols(dataframe=df)\n",
        "    #-----Start of ML-----\n",
        "    #Get X, y as individual dataframes\n",
        "    X, y = get_xy(dataframe=df)\n",
        "    X_train, y_train = get_xy(dataframe=df.loc[(df[\"As of date\"] == train_date)])\n",
        "    X_test, y_test = get_xy(dataframe=df.loc[(df[\"As of date\"] == test_date)])\n",
        "    #Supervised train\n",
        "    train_df = join_df(X_train,y_train)\n",
        "    X_train, y_train = get_scaled_xy(dataframe=train_df)\n",
        "    #Supervised test\n",
        "    test_df = join_df(X_test,y_test)\n",
        "    base_test_probability = get_base_prob(dataframe=test_df)\n",
        "    X_test, y_test = get_scaled_xy(dataframe=test_df)\n",
        "    #Unsupervised\n",
        "    df = join_df(X,y)\n",
        "    #base_probability = get_base_prob(dataframe=df)\n",
        "    X, y = get_scaled_xy(dataframe=df)\n",
        "    \n",
        "    EP, bestalgo, summary = get_EP_results(K_Means_nclusters=K_Means_nclusters,Mean_Shift_min_df_len=Mean_Shift_min_df_len,base_test_prob=base_test_probability,\\\n",
        "                                           X_train=X_train, y_train=y_train,X_test=X_test, y_test=y_test,train_date=train_date,test_date=test_date)\n",
        "    store_results(result_to_store=EP,resultdict=result,train_date=train_date,test_date=test_date,hurdle=hurdle)\n",
        "    title = f'{hurdle*100}%//{train_date}//{test_date}'\n",
        "    return title, EP\n",
        "    #-----End of program-----\n",
        "    \n",
        "import concurrent.futures as cf\n",
        "from itertools import repeat\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def main(hurdlelist,datepairs,result):\n",
        "    with cf.ProcessPoolExecutor() as executor:#ThreadPoolExecutor() as executor:\n",
        "      x = [executor.submit(test,x,y,z) for x,y,z in zip(hurdlelist,datepairs,repeat(result))]\n",
        "      for i in cf.as_completed(x):\n",
        "            k, v = i.result()\n",
        "            result4[k] = v #result or result4?\n",
        "\n",
        "\n",
        "start = timer()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  PATH = '/content/drive/My Drive/YOUR_PATH_TO_DATA'\n",
        "  #args = [(x,y,result4) for x in hurdlelist for y in datepairs]\n",
        "  #Lists to iterate over\n",
        "  #datepairs = [['2010-06-30','2011-06-30']]#,['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]\n",
        "  datepairs = [['2011-06-30','2012-06-30'],['2011-06-30','2013-06-30'],['2011-06-30','2014-06-30']]\n",
        "  hurdlelist = [1,2,3,4,5] # >x*100% returns in the forward 5Y period\n",
        "  datepairs2 = [['2010-06-30','2011-06-30'],['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]*5\n",
        "  hurdlelist2 = [1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5] # >x*100% returns in the forward 5Y period\n",
        "  \n",
        "  result4 = {}\n",
        "  main(hurdlelist2,datepairs2,result4)\n",
        "  '''\n",
        "  p = Pool(processes=20)\n",
        "  data = p.starmap(test, zip(hurdlelist2,datepairs2,repeat(result4)))\n",
        "  p.close()\n",
        "  result5 = dict(data)\n",
        "  '''\n",
        "end = timer()\n",
        "print (end-start)\n",
        "\n",
        "result4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtE1vjovuaMV"
      },
      "source": [
        "# Model Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTRNSg_OcEOU"
      },
      "source": [
        "from numpy import mean\n",
        "\n",
        "algoDT1 = []\n",
        "algoKNN1 = []\n",
        "algoRF1 = []\n",
        "algoSVM1 = []\n",
        "algoKMeans1 = []\n",
        "algoMeanShift1 = []\n",
        "\n",
        "for k,v in result3.items():\n",
        "  algoDT1.append(v['DT']) if v['DT'] != -v['base_test_prob'] else None\n",
        "  algoKNN1.append(v['KNN']) if v['KNN'] != -v['base_test_prob'] else None\n",
        "  algoRF1.append(v['RF']) if v['RF'] != -v['base_test_prob'] else None\n",
        "  algoSVM1.append(v['SVM']) if v['SVM'] != -v['base_test_prob'] else None\n",
        "  algoKMeans1.append(v['KMeans']) if v['KMeans'] != -v['base_test_prob'] else None\n",
        "\n",
        "algoDT2 = []\n",
        "algoKNN2 = []\n",
        "algoRF2 = []\n",
        "algoSVM2 = []\n",
        "algoKMeans2 = []\n",
        "algoMeanShift2 = []\n",
        "\n",
        "for k,v in result4.items():\n",
        "  algoDT2.append(v['DT']) if v['DT'] != -v['base_test_prob'] else None\n",
        "  algoKNN2.append(v['KNN']) if v['KNN'] != -v['base_test_prob'] else None\n",
        "  algoRF2.append(v['RF']) if v['RF'] != -v['base_test_prob'] else None\n",
        "  algoSVM2.append(v['SVM']) if v['SVM'] != -v['base_test_prob'] else None\n",
        "  algoKMeans2.append(v['KMeans']) if v['KMeans'] != -v['base_test_prob'] else None\n",
        "\n",
        "AVGdict = {\n",
        "    'AVGalgoDT1' : [mean(algoDT1),len(algoDT1)],\n",
        "    'AVGalgoKNN1' : [mean(algoKNN1),len(algoKNN1)],\n",
        "    'AVGalgoRF1' : [mean(algoRF1),len(algoRF1)],\n",
        "    'AVGalgoSVM1' : [mean(algoSVM1),len(algoSVM1)],\n",
        "    'AVGalgoKMeans1' : [mean(algoKMeans1),len(algoKMeans1)],\n",
        "    'AVGalgoDT2' : [mean(algoDT2),len(algoDT2)],\n",
        "    'AVGalgoKNN2' : [mean(algoKNN2),len(algoKNN2)],\n",
        "    'AVGalgoRF2' : [mean(algoRF2),len(algoRF2)],\n",
        "    'AVGalgoSVM2' : [mean(algoSVM2),len(algoSVM2)],\n",
        "    'AVGalgoKMeans2' : [mean(algoKMeans2),len(algoKMeans2)]}\n",
        "\n",
        "AVGdict = {k: [round(v[0],2),v[1]] for k, v in AVGdict.items()}\n",
        "\n",
        "listdict = {\n",
        "    'DT1' : [algoDT1,len(algoDT1)],\n",
        "    'KNN1' : [algoKNN1,len(algoKNN1)],\n",
        "    'RF1' : [algoRF1,len(algoRF1)],\n",
        "    'SVM1' : [algoSVM1,len(algoSVM1)],\n",
        "    'KMeans1' : [algoKMeans1,len(algoKMeans1)],\n",
        "    'DT2' : [algoDT2,len(algoDT2)],\n",
        "    'KNN2' : [algoKNN2,len(algoKNN2)],\n",
        "    'RF2' : [algoRF2,len(algoRF2)],\n",
        "    'SVM2' : [algoSVM2,len(algoSVM2)],\n",
        "    'KMeans2' : [algoKMeans2,len(algoKMeans2)]}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Notes:\n",
        "DT is good for a little additional pct over base prob\n",
        "X - KMeans is only good in 1 year, (not suitable for usage)\n",
        "KNN is good for hurdle=1,2, cannot predict above that\n",
        "RF is very predictive, but only gives predictions for a few periods\n",
        "X - SVM is bad\n",
        "RANK - RF, KNN, DT           X - KMeans, SVM\n",
        "'''\n",
        "AVGdict\n",
        "#listdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf89QKGmkr2C"
      },
      "source": [
        "def generate_model_report(y_actual,y_predict):\n",
        "  print(f\"Accuracy:\\t {accuracy_score(y_actual,y_predict)}\" )\n",
        "  print(f\"Precision:\\t {precision_score(y_actual,y_predict)}\" )\n",
        "  print(f\"Recall:\\t\\t {recall_score(y_actual,y_predict)}\" )\n",
        "  print(f\"F1 Score:\\t {f1_score(y_actual,y_predict)}\" )\n",
        "  pass\n",
        "\n",
        "def generate_auc_roc_curve(clf, X_test):\n",
        "  y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
        "  fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba)\n",
        "  auc = roc_auc_score(y_test, y_pred_proba)\n",
        "  plt.plot(fpr,tpr,label=\"AUC ROC Curve with Area Under the curve =\"+str(auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA1SY1kbIM1q"
      },
      "source": [
        "#pd.crosstab(pd.Series(y_predict,name ='Predicted'), pd.Series(y_test, name ='Actual'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Rx7JfyZE3X"
      },
      "source": [
        "#generate_model_report(y_test,y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNENRV5iZmxV"
      },
      "source": [
        "#generate_auc_roc_curve(clf, X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1h6gQ47klm5"
      },
      "source": [
        "# Backtester (Individual algos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11NPcHZA0CZG"
      },
      "source": [
        "import itertools\n",
        "#List for iteration\n",
        "PATH = '/content/drive/My Drive/YOUR_PATH_TO_DATA'\n",
        "#datepairs = ([f'{2000+i}-06-30',f'{2000+i+1}-06-30'] for i in range(14)) #2000 to 2014\n",
        "hurdlelist = (i for i in range(1,2)) # >x*100% returns in the forward 5Y period\n",
        "\n",
        "#List for iteration\n",
        "#datepairs = [['2010-06-30','2011-06-30'],['2011-06-30','2012-06-30'],['2012-06-30','2013-06-30'],['2013-06-30','2014-06-30']]\n",
        "#hurdlelist = [1,2,3,4,5] # >x*100% returns in the forward 5Y period\n",
        "bt_result = {}\n",
        "\n",
        "for hurdle in hurdlelist:\n",
        "  datepairs = ([f'{2000+i}-06-30',f'{2000+i+1}-06-30'] for i in range(14)) #2000 to 2014\n",
        "  for datepair in datepairs:\n",
        "    #-----Setting Parameters-----\n",
        "    train_date = datepair[0]\n",
        "    test_date = datepair[1]\n",
        "    hurdle = hurdle\n",
        "    K_Means_nclusters = 2\n",
        "    Mean_Shift_min_df_len = 0.1\n",
        "    #-----Start main program-----\n",
        "    df = get_df(PATH)\n",
        "    df = df.loc[(df[\"As of date\"] == train_date)|(df[\"As of date\"] == test_date)]\n",
        "    add_hurdle_col(dataframe=df,hurdle=hurdle)\n",
        "    df = drop_useless_cols(dataframe=df)\n",
        "    clean_div_yield_col(dataframe=df)\n",
        "    clean_KMB_all_cols(dataframe=df)\n",
        "    #-----ADDITIONS-----\n",
        "    #df = df.loc[(df['5Y AVG P/E']!=-10000)&(df['5Y AVG P/FCF']!=-10000)] ##### remove negative 5y returns companies\n",
        "    #df.drop(['CAGR of Revenue:CQ T12M','Gr PoP of Avg Shares for EPS:Q','Gr PoP of Avg Shares for EPS:Q.1','Dvd Yld'], axis=1, inplace=True)\n",
        "    #-----END OF ADDITIONS-----\n",
        "    #-----Start of ML-----\n",
        "    #Get X, y as individual dataframes\n",
        "    X, y = get_xy(dataframe=df)\n",
        "    X_train, y_train = get_xy(dataframe=df.loc[(df[\"As of date\"] == train_date)])\n",
        "    X_test, y_test = get_xy(dataframe=df.loc[(df[\"As of date\"] == test_date)])\n",
        "    #Supervised train\n",
        "    train_df = join_df(X_train,y_train)\n",
        "    X_train, y_train = get_scaled_xy(dataframe=train_df)\n",
        "    #Supervised test\n",
        "    test_df = join_df(X_test,y_test)\n",
        "    base_test_probability = get_base_prob(dataframe=test_df)\n",
        "    X_test, y_test = get_scaled_xy(dataframe=test_df)\n",
        "    #Unsupervised\n",
        "    df2 = join_df(X,y)\n",
        "    #base_probability = get_base_prob(dataframe=df)\n",
        "    X, y = get_scaled_xy(dataframe=df2)\n",
        "    #-----End of data retrieval-----\n",
        "    #-----BACKTESTER-----\n",
        "    #print(f'Hurdle: {hurdle} // Train Date: {train_date} // Test Date: {test_date}')\n",
        "    run_result = {}\n",
        "    for i in range(10):\n",
        "      # Random Forest\n",
        "      clf = RandomForestClassifier(n_jobs=-1) #neighbors.KNeighborsClassifier() #DecisionTreeClassifier() #RandomForestClassifier(n_jobs=-1)\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_predict = clf.predict(X_test)\n",
        "      #print(precision_score(y_test,y_predict,zero_division=0))\n",
        "      #Precision x (hurdle+1) > 1\n",
        "      #print(precision_score(y_test,y_predict,zero_division=0)*(hurdle+1))\n",
        "      result = df[(df['As of date']==test_date)]\n",
        "      result.reset_index(inplace = True)\n",
        "      result = result.join(pd.DataFrame(y_predict))\n",
        "      result = result[(result[0] == 1)]\n",
        "      run_result[f'Run: {i}'] = round(result['Fwd 5Y Return'].mean()*100,0)\n",
        "    bt_result[f'Hurdle: {hurdle} // Train Date: {train_date} // Test Date: {test_date}'] = pd.Series([*run_result.values()]).mean()\n",
        "  print (f'Run: {hurdle}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMo4K_XfQ7cy"
      },
      "source": [
        "bt_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aB0FlUO_Wh5"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6EEkkwouhi7"
      },
      "source": [
        "# Future improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxCU7eXZcQEh"
      },
      "source": [
        "# Normalize with max(\"x/x(absmax)\"), l1(\"x/sum(x)\") , l2(euclidean dist)\n",
        "# Optimize with numba, cprofile, multiprocessing etc\n",
        "# Binning of returns?\n",
        "# https://www.oreilly.com/library/view/machine-learning-with/9781491989371/ch04.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1VYaoDAlNp4"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VoPs8oWU5_2"
      },
      "source": [
        "import multiprocessing as mp\n",
        "print(\"Number of processors: \", mp.cpu_count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6kXDlCmk2di"
      },
      "source": [
        "# Other checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgKlsn3MbN4Y"
      },
      "source": [
        "#Check for unbalanced data\n",
        "unique_classes = list(os_df['Y'].unique())\n",
        "print(unique_classes)\n",
        "    \n",
        "out_dict = {}\n",
        "for classes in unique_classes:\n",
        "    out_dict[classes] = os_df.shape[0]/((os_df.loc[os_df['Y'] == classes].shape[0])\n",
        "                                     *len(unique_classes))\n",
        "print(out_dict)\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#Before resampling\n",
        "print(Counter(y))\n",
        "\n",
        "#After resampling\n",
        "X_res, y_res = SMOTE(random_state=0).fit_resample(X, y)\n",
        "print(Counter(y_res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rQqmjQt-zEd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpYMY3NKVKkk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}